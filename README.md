# DATA-VISUALISATION-USING-POWER-BI-WITH-WEB-SCRAPPING

I am excited to share my recent project on web scraping with Python using the BeautifulSoup, requests, and pandas libraries. In this project, I created a script that extracts quotes, author names, and tags from the website https://lnkd.in/d8UJakSv and stores them in an excel file.

Web scraping is a powerful technique for extracting data from websites and can be used in various fields such as data analysis, research, and business intelligence. In this project, I used the BeautifulSoup library to parse HTML content and extract relevant data, the requests library to send HTTP requests and retrieve web page content, and the pandas library to manipulate and analyze the extracted data.

This project is a great starting point for anyone interested in learning about web scraping and exploring the vast amounts of data available on the internet. It provides a simple and efficient way to navigate through HTML tags and elements, handle cookies and headers, and manipulate and analyze data.

If you're interested in checking out the project, you can find it on my GitHub repository. Feel free to leave any feedback or questions in the comments, and happy web scraping!


Web scraping, also known as web data extraction, is the process of extracting information from websites. This information can include text, images, videos, and other types of data that are publicly available on the internet. Web scraping can be done manually, but it is typically automated using software tools known as web scrapers or crawlers.

The process of web scraping involves three main steps: sending a request to a website, parsing the HTML or XML content, and extracting the relevant information. The first step involves sending a request to the website using a web scraper or crawler. The scraper sends a request to the website's server, which responds with the HTML or XML content of the webpage. The scraper then parses this content to identify the relevant data that needs to be extracted.

There are various tools and programming languages that can be used to create web scrapers, including Python, Ruby, JavaScript, and many others. These tools typically provide a set of libraries and modules that allow developers to build robust web scrapers. For instance, Python has libraries like BeautifulSoup and Scrapy that make it easy to parse HTML and XML content, while Ruby has Nokogiri.

Web scraping has many practical applications, such as price monitoring, market research, data aggregation, and content curation. For instance, an e-commerce business can use web scraping to monitor the prices of its competitors and adjust its own pricing strategy accordingly. A media company can use web scraping to gather news articles from various sources and curate them into a single newsfeed.

However, it is important to note that web scraping can be a controversial practice, as some website owners consider it a form of theft or copyright infringement. Therefore, it is important to be aware of the legal and ethical implications of web scraping and to use it responsibly and ethically. Some websites may also have measures in place to prevent web scraping, such as CAPTCHAs or other forms of anti-scraping technology.

In conclusion, web scraping is a powerful tool that can provide valuable insights and data to businesses and individuals. However, it should be used with caution and in compliance with legal and ethical standards.
